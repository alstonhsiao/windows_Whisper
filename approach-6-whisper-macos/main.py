"""
macOS èªéŸ³è½‰æ–‡å­—å·¥å…· â€” æ–¹æ¡ˆå…­ï¼šOpenAI Whisperï¼ˆmacOSï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  pip install -r requirements.txt
  python main.py

æ“ä½œï¼š
  - æŒ‰ä½ F9 â†’ é–‹å§‹éŒ„éŸ³ï¼ˆè½åˆ°æç¤ºéŸ³å¾Œé–‹å§‹èªªè©±ï¼‰
  - æ”¾é–‹ F9 â†’ åœæ­¢éŒ„éŸ³ â†’ è‡ªå‹•è¾¨è­˜ â†’ è²¼ä¸Šæ–‡å­—åˆ°æ¸¸æ¨™ä½ç½®
  - æŒ‰ Ctrl+C çµæŸç¨‹å¼

macOS æ¬Šé™éœ€æ±‚ï¼š
  - ç³»çµ±è¨­å®š â†’ éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ â†’ éº¥å…‹é¢¨ â†’ å…è¨± Terminal / IDE
  - ç³»çµ±è¨­å®š â†’ éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ â†’ è¼”åŠ©ä½¿ç”¨ â†’ å…è¨± Terminal / IDE
  - ç³»çµ±è¨­å®š â†’ éš±ç§æ¬Šèˆ‡å®‰å…¨æ€§ â†’ è¼¸å…¥ç›£æ§ â†’ å…è¨± Terminal / IDE

èˆ‡ approach-3ï¼ˆWindows Whisperï¼‰å·®ç•°ï¼š
  - é‡å° macOS å„ªåŒ–ï¼ˆæç¤ºéŸ³ã€Command+Vã€fcntl å–®ä¾‹é–ã€rumps é¸å–®åˆ—ï¼‰
  - ç„¡ winsound / Windows Mutex ä¾è³´
"""

from __future__ import annotations

import json
import os
import re
import sys
import tempfile
import threading
import time
from pathlib import Path

import numpy as np
import pyperclip
import requests
import sounddevice as sd
import soundfile as sf


# ---------------------------------------------------------------------------
# é˜²é‡è¤‡å•Ÿå‹•ï¼ˆfcntl lockfileï¼‰
# ---------------------------------------------------------------------------

_lock_file_handle = None


def ensure_single_instance(app_name: str = "WhisperVoiceTypingMac") -> bool:
    """ä½¿ç”¨ lockfile + fcntl.flock é˜²æ­¢é‡è¤‡å•Ÿå‹•"""
    global _lock_file_handle
    lock_path = Path(tempfile.gettempdir()) / f"{app_name}.lock"

    try:
        import fcntl
        _lock_file_handle = open(lock_path, "w")
        fcntl.flock(_lock_file_handle, fcntl.LOCK_EX | fcntl.LOCK_NB)
        _lock_file_handle.write(str(os.getpid()))
        _lock_file_handle.flush()
        return True
    except (IOError, OSError):
        print(f"âš ï¸  ç¨‹å¼å·²ç¶“åœ¨åŸ·è¡Œä¸­ï¼ˆlock: {lock_path}ï¼‰")
        return False
    except ImportError:
        return True


# ---------------------------------------------------------------------------
# macOS é¸å–®åˆ—åœ–ç¤ºï¼ˆrumps â€” å¯é¸ï¼‰
# ---------------------------------------------------------------------------

_status_label = {"text": "â¸ å¾…æ©Ÿ"}


def try_start_menubar():
    """å˜—è©¦å•Ÿå‹• macOS é¸å–®åˆ—åœ–ç¤ºï¼ˆrumpsï¼‰ï¼Œå¤±æ•—å‰‡è·³é"""
    try:
        import rumps

        class VoiceTypingApp(rumps.App):
            def __init__(self):
                super().__init__("ğŸ¤", quit_button="çµæŸç¨‹å¼")
                self.menu = [rumps.MenuItem("Whisper èªéŸ³è½‰æ–‡å­—"), None]

            @rumps.timer(1)
            def update_title(self, _):
                self.title = _status_label["text"]

        app = VoiceTypingApp()
        threading.Thread(target=app.run, daemon=True).start()
        return True
    except ImportError:
        print("â„¹ï¸  rumps æœªå®‰è£ï¼Œè·³éé¸å–®åˆ—åœ–ç¤ºï¼ˆåŠŸèƒ½ä¸å—å½±éŸ¿ï¼‰")
        return False
    except Exception:
        return False


def set_menubar_state(state: str):
    """æ›´æ–°é¸å–®åˆ—åœ–ç¤ºç‹€æ…‹"""
    states = {
        "idle":       "â¸ å¾…æ©Ÿ",
        "recording":  "ğŸ”´ éŒ„éŸ³ä¸­",
        "processing": "ğŸ”„ è¾¨è­˜ä¸­",
        "error":      "âš ï¸ éŒ¯èª¤",
    }
    _status_label["text"] = states.get(state, "â¸ å¾…æ©Ÿ")


# ---------------------------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------------------------

def get_base_dir() -> Path:
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path(__file__).parent


def load_config() -> dict:
    """å¾ config.json è¼‰å…¥è¨­å®š"""
    config = {
        "api_key": "",
        "model": "whisper-1",
        "language": "zh",
        "temperature": 0.0,
        "response_format": "json",
        "sample_rate": 16000,
        "channels": 1,
        "hotkey": "f9",
        "prompt": "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚åŒ…å«ï¼šè•­æ·³äº‘, å‘¨èŠ·è“, åˆä½œå» å•†åŠ æ¨¡, å°ˆæ¡ˆ Tahoe, n8n, Zeaburã€‚",
        "regex_rules": [
            {"pattern": r"N8n|N 8 n", "replacement": "n8n", "flags": "IGNORECASE"}
        ],
    }

    base = get_base_dir()
    config_paths = [
        base / "config.json",
        Path.home() / ".whisper-voice-typing" / "config.json",
    ]

    for cp in config_paths:
        if cp.exists():
            with open(cp, encoding="utf-8") as f:
                user_cfg = json.load(f)
            if "api" in user_cfg:
                config["api_key"] = user_cfg["api"].get("openai_api_key", config["api_key"])
                config["model"] = user_cfg["api"].get("model", config["model"])
                config["language"] = user_cfg["api"].get("language", config["language"])
                config["temperature"] = user_cfg["api"].get("temperature", config["temperature"])
            if "prompt" in user_cfg:
                config["prompt"] = user_cfg["prompt"].get("text", config["prompt"])
            if "hotkey" in user_cfg:
                config["hotkey"] = user_cfg["hotkey"].get("record_key", config["hotkey"]).lower()
            if "post_process" in user_cfg:
                config["regex_rules"] = user_cfg["post_process"].get("regex_rules", config["regex_rules"])
            break

    # .env.local è¦†è“‹
    env_file = base / ".env.local"
    if not env_file.exists():
        env_file = base.parent / ".env.local"
    if env_file.exists():
        with open(env_file, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, _, value = line.partition("=")
                    os.environ.setdefault(key.strip(), value.strip())

    config["api_key"] = os.environ.get("OPENAI_API_KEY", config["api_key"])

    return config


# ---------------------------------------------------------------------------
# éŒ„éŸ³æ¨¡çµ„
# ---------------------------------------------------------------------------

class AudioRecorder:
    """ä½¿ç”¨ sounddevice åœ¨è¨˜æ†¶é«”ä¸­éŒ„éŸ³"""

    def __init__(self, sample_rate: int = 16000, channels: int = 1):
        self.sample_rate = sample_rate
        self.channels = channels
        self.is_recording = False
        self._frames: list[np.ndarray] = []
        self._stream: sd.InputStream | None = None

    def start(self):
        self._frames = []
        self.is_recording = True
        self._stream = sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            dtype="int16",
            callback=self._callback,
        )
        self._stream.start()

    def _callback(self, indata, frames, time_info, status):
        if self.is_recording:
            self._frames.append(indata.copy())

    def stop(self) -> str | None:
        self.is_recording = False
        if self._stream:
            self._stream.stop()
            self._stream.close()
            self._stream = None

        if not self._frames:
            return None

        audio_data = np.concatenate(self._frames, axis=0)
        duration = len(audio_data) / self.sample_rate
        if duration < 0.5:
            return None

        wav_path = os.path.join(tempfile.gettempdir(), "whisper_voice_mac.wav")
        sf.write(wav_path, audio_data, self.sample_rate, subtype="PCM_16")
        return wav_path

    @property
    def buffer_samples(self) -> int:
        return sum(len(f) for f in self._frames)


# ---------------------------------------------------------------------------
# Whisper API
# ---------------------------------------------------------------------------

def transcribe(wav_path: str, config: dict) -> str:
    url = "https://api.openai.com/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {config['api_key']}"}

    with open(wav_path, "rb") as f:
        files = {"file": ("voice.wav", f, "audio/wav")}
        data = {
            "model": config["model"],
            "language": config["language"],
            "temperature": str(config["temperature"]),
            "response_format": config["response_format"],
            "prompt": config["prompt"],
        }
        response = requests.post(url, headers=headers, files=files, data=data, timeout=30)

    response.raise_for_status()
    return response.json()["text"]


# ---------------------------------------------------------------------------
# å¾Œè™•ç†
# ---------------------------------------------------------------------------

def apply_corrections(text: str, regex_rules: list[dict]) -> str:
    for rule in regex_rules:
        flags = 0
        flag_str = rule.get("flags", "")
        if "IGNORECASE" in flag_str.upper():
            flags |= re.IGNORECASE
        text = re.sub(rule["pattern"], rule["replacement"], text, flags=flags)
    return text.strip()


# ---------------------------------------------------------------------------
# Beepï¼ˆmacOS åŸç”Ÿæç¤ºéŸ³ï¼‰
# ---------------------------------------------------------------------------

def beep():
    try:
        os.system("afplay /System/Library/Sounds/Tink.aiff &")
    except Exception:
        print("\a", end="", flush=True)


# ---------------------------------------------------------------------------
# è²¼ä¸Šï¼ˆmacOSï¼šosascript â†’ å°å‰æ™¯è¦–çª—ç™¼é€ Cmd+Vï¼Œæ¯” pynput æ›´å¯é ï¼‰
# ---------------------------------------------------------------------------

def paste_text(text: str):
    import subprocess

    # 1. å¯«å…¥å‰ªè²¼ç°¿
    pyperclip.copy(text)

    # 2. çŸ­æš«ç­‰å¾…ï¼Œè®“ç„¦é»æœ‰æ™‚é–“å›åˆ°ç›®æ¨™è¦–çª—
    time.sleep(0.15)

    # 3. ç”¨ osascript å°ç•¶å‰å‰æ™¯ App ç™¼é€ Cmd+V
    result = subprocess.run(
        ["osascript", "-e",
         'tell application "System Events" to keystroke "v" using command down'],
        capture_output=True,
    )

    # å¦‚æœ osascript å¤±æ•—ï¼ˆç½•è¦‹ï¼‰ï¼Œfallback åˆ° pynput
    if result.returncode != 0:
        from pynput.keyboard import Controller, Key
        kb = Controller()
        kb.press(Key.cmd)
        kb.press("v")
        kb.release("v")
        kb.release(Key.cmd)


# ---------------------------------------------------------------------------
# ä¸»ç¨‹å¼
# ---------------------------------------------------------------------------

def main():
    # â”€â”€ 1. é˜²é‡è¤‡å•Ÿå‹• â”€â”€
    if not ensure_single_instance():
        sys.exit(0)

    # â”€â”€ 2. è¼‰å…¥è¨­å®š â”€â”€
    config = load_config()

    if not config["api_key"] or config["api_key"] == "YOUR_OPENAI_API_KEY_HERE":
        print("âŒ éŒ¯èª¤ï¼šè«‹è¨­å®š OPENAI_API_KEY")
        print("   æ–¹æ³• 1ï¼šåœ¨ .env.local ä¸­è¨­å®š OPENAI_API_KEY=ä½ çš„Key")
        print("   æ–¹æ³• 2ï¼šåœ¨ config.json ä¸­å¡«å…¥ openai_api_key")
        sys.exit(1)

    # â”€â”€ 3. macOS é¸å–®åˆ—åœ–ç¤ºï¼ˆå¯é¸ï¼‰ â”€â”€
    try_start_menubar()

    # â”€â”€ 4. åˆå§‹åŒ–éŒ„éŸ³ â”€â”€
    recorder = AudioRecorder(
        sample_rate=config["sample_rate"],
        channels=config["channels"],
    )
    recording = False
    lock = threading.Lock()

    print("=" * 50)
    print("ğŸ¤ Whisper èªéŸ³è½‰æ–‡å­—å·¥å…·å·²å•Ÿå‹•ï¼ˆmacOSï¼‰")
    print(f"   ç†±éµï¼šæŒ‰ä½ {config['hotkey'].upper()} èªªè©±ï¼Œæ”¾é–‹å¾Œè‡ªå‹•è¾¨è­˜")
    print(f"   èªè¨€ï¼š{config['language']}")
    print("   çµæŸï¼šCtrl+C")
    print("=" * 50)

    # â”€â”€ 5. ç†±éµåµæ¸¬ â”€â”€
    from pynput import keyboard

    hotkey_map = {f"f{i}": getattr(keyboard.Key, f"f{i}") for i in range(1, 13)}
    target_key = hotkey_map.get(config["hotkey"].lower(), keyboard.Key.f9)

    def on_press(key):
        nonlocal recording
        if key != target_key:
            return
        with lock:
            if recording:
                return
            recording = True

        set_menubar_state("recording")
        print("ğŸ”´ éŒ„éŸ³ä¸­... ï¼ˆæ”¾é–‹æŒ‰éµåœæ­¢ï¼‰")
        recorder.start()

        for _ in range(60):
            time.sleep(0.05)
            if recorder.buffer_samples > 4000:
                beep()
                break

    def on_release(key):
        nonlocal recording
        if key != target_key:
            return
        with lock:
            if not recording:
                return
            recording = False

        wav_path = recorder.stop()
        if not wav_path:
            set_menubar_state("idle")
            print("âš ï¸  éŒ„éŸ³æ™‚é–“å¤ªçŸ­ï¼Œå·²å¿½ç•¥")
            return

        set_menubar_state("processing")
        print("ğŸ”„ è¾¨è­˜ä¸­...")

        try:
            raw_text = transcribe(wav_path, config)
        except requests.exceptions.HTTPError as e:
            status = e.response.status_code if e.response else "?"
            msg = {401: "API Key ç„¡æ•ˆ", 429: "è«‹æ±‚éæ–¼é »ç¹"}.get(status, f"API éŒ¯èª¤ HTTP {status}")
            print(f"âŒ {msg}")
            set_menubar_state("error")
            time.sleep(2)
            set_menubar_state("idle")
            return
        except requests.exceptions.Timeout:
            print("âŒ ç¶²è·¯é€¾æ™‚")
            set_menubar_state("error")
            time.sleep(2)
            set_menubar_state("idle")
            return
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            set_menubar_state("error")
            time.sleep(2)
            set_menubar_state("idle")
            return

        final_text = apply_corrections(raw_text, config["regex_rules"])
        if not final_text:
            print("âš ï¸  è¾¨è­˜çµæœç‚ºç©º")
            set_menubar_state("idle")
            return

        paste_text(final_text)
        print(f"âœ… å·²è²¼ä¸Šï¼š{final_text}")
        set_menubar_state("idle")

    with keyboard.Listener(on_press=on_press, on_release=on_release) as listener:
        listener.join()


if __name__ == "__main__":
    main()
